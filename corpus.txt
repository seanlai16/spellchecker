DEEP LEARNING FOR SENTIMENT ANALYSIS FOR
AMAZON REVIEW DATA
CHAN KAI MING
ASIA PACIFIC UNIVERSITY OF TECHNOLOGY AND INNOVATION
(APU)
ii
DEEP LEARNING FOR SENTIMENT ANALYSIS FOR
AMAZON REVIEW DATA
CHAN KAI MING
A thesis submitted in fulfilment of the
requirements for the award of the degree of
MSC IN DATA SCIENCE AND BUSINESS ANALYTICS
ASIA PACIFIC UNIVERSITY OF TECHNOLOGY & INNOVATION (APU)
GRADUATE SCHOOL OF TECHNOLOGY
iii
DECEMBER 2024
DECLARATION OF THESIS CONFIDENTIALITY
Author’s full name: Chan Kai Ming
IC No./Passport No.: 880904-07-5223
Thesis/Project title: DEEP LEARNING FOR SENTIMENT ANALYSIS FOR
AMAZON REVIEW DATA
I declare that this thesis is classified as:
 CONFIDENTIAL
 RESTRICTED
 OPEN ACCESS
I acknowledged that Asia Pacific University of Technology & Innovation (APU) reserves the
right as follows:
1. The thesis is the property of Asia Pacific University of Technology & Innovation
(APU).
2. The Library of Asia Pacific University of Technology & Innovation (APU) has the right
to make copies for the purpose of research only.
3. The Library has the right to make copies of the thesis for academic exchange.
Author’s Signature: …Chan Kai Ming………………
Date: 28 December 2024
Supervisor’s Name: Assoc. Prof. Dr. Raja Rajeswari
Date: 28 December 2024
Signature: ……………………………
iv
DECLARATION OF SUPERVISOR(S)
“ We hereby declare that We have read this thesis and in our
opinion this thesis is sufficient in terms of scope and quality for the
award of the degree of
MSC IN DATA SCIENCE AND BUSINESS ANALYTICS
Name of Supervisor: Assoc. Prof. Dr. Raja Rajeswari
Signature: ……………………………
Date: 28 December 2024
v
Table of Contents
Contents
Table of Contents ..................................................................................................... v
Abstract ................................................................................................................. vi
List of tables ........................................................................................................... vii
List of figures ......................................................................................................... viii
List of abbreviations ................................................................................................. x
Assignment 1 Deep Learning Methods for sentiment analysis ..................................... 1
1.1Introduction ........................................................................................................ 1
1.2 Domain and problem selected ......................................................................... 1
1.3 Aim and objective ............................................................................................ 1
1.4 Literature Review/Previous Works .................................................................... 2
1.5 Comparison and analysis of the literature review ............................................... 5
1.6 Overview of the implementation ....................................................................... 6
1.7 Dataset used. ................................................................................................. 7
1.8 Selected Model Architecture. ........................................................................... 7
1.9 Selected evaluation metrics and criteria. .......................................................... 8
Assignment 2 Deep Learning Model Implementation for Amazon review sentiment
analysis. .................................................................................................................. 9
2.1 Data preprocessing. ........................................................................................ 9
2.2 Data Transformation. ..................................................................................... 10
2.3 Base Model implementation and evaluation. ................................................... 12
2.4 Hyperparameter Tuning of the base model. ..................................................... 18
2.5 Critical analysis and comparison of base and hypertuned model. ..................... 23
2.6 Critical analysis and comparison with other research. ..................................... 25
3. Conclusion. .................................................................................................... 26
4. Future work and recommendations. ................................................................. 26
References. ........................................................................................................... 27
vi
Abstract
Due to increasing use of social media and online shopping services sentiment analysis which
can derive the views and opinions have become increasingly important for organizations as is
allow them to identify positive and negative sentiments on strategies allowing organizations
to understand and adjust strategies based on this sentiments. This project attempts to build 4
deep learning models LSTM,CNN,DNN LSTM,RNN to detect and classify sentiments for
Amazon review data. The results will be validated and evaluated via
accuracy,loss,precision,F1 score and recall. The CNN tuned model achieved 88% accuracy
and was able to classify the review accurately which will be useful for
corporations/organizations.
vii
List of tables
Table 1: Comparison and analysis of the literature review 5
Table 2: Comparison of results of own base and hypertuned model 23
Table 3: Comparison of results with other research 25
viii
List of figures
Figure 1: Preview of dataset content 7
Figure 2: Preprocessing of dataset 9
Figure 3: Application of preprocessing function to the 60001 review dataset. 10
Figure 4: Before(Left) and after(Right) preprocessing of review text 10
Figure 5: Balancing attempt distribution 10
Figure 6: Tokenization and padding 11
Figure 7: LSTM base model 12
Figure 8: LSTM base model accuracy and loss 12
Figure 9: LSTM base model classification report 12
Figure 10: CNN base Model 13
Figure 11: CNN base model accuracy and loss 13
Figure 12: CNN based model classification report 14
Figure 13: DNN LSTM base model 15
Figure 14: DNN LSTM accuracy and loss 15
Figure 15: DNN LSTM classification report 15
Figure 16: RNN base model 16
Figure 17: RNN base model accuracy and loss 17
Figure 18: RNN base model classification report 17
Figure 19: LSTM tuned model 18
Figure 20: LSTM tuned model accuracy and loss 18
Figure 21: LSTM tuned model classification report 18
Figure 22: CNN tuned model 19
Figure 23: CNN tuned model accuracy and loss 19
Figure 24: CNN tuned model classification report 20
Figure 25: DNN LSTM tuned model 21
Figure 26: DNN LSTM tuned model accuracy and loss 21
ix
Figure 27: DNN LSTM tuned model classification report 21
Figure 28: RNN tuned model 22
Figure 29: RNN tuned model accuracy and loss 22
Figure 30: RNN tuned model classification report 23
Figure 31: Sentiment analysis function 26
x
List of abbreviations
CNN……Convolutional Neural Network
LSTM…..Long Short Term Memorry
DNN…..Deep Neural Network
RNN….Recurrent Neural Network
NGO….Non-Government Organization
FNN….Feed Forward Neural Network
SVM….Support Vector Machine
TP…….True Positive
TN……True Negative
FP…....False Positive
FN……False Negative
DNN LSTM…..Deep Neural Network Long Short Term Memory hybrid
1
Assignment 1 Deep Learning Methods for sentiment
analysis
1.1Introduction
Sentiment analysis is an important domain that is highly regarded by business, NGOs and
political parties as is allow opinions, review and insights to be derived from analyzing it.
Positive view and sentiments are important for the successes of organizations as it allows for
better campaigns, marketing, products and services.
Deep learning methods are important is allow for effective sentiment analysis as they
generally perform better than traditional machine learning methods and can derive and learn
context, meaning and patterns well.
1.2 Domain and problem selected
A lot of companies like Amazon, Shopee and Lazada have reviews submitted on offerings
and products by the companies. Social medias like X, facebook and Instagram have many
text containing views and sentiment. This sentiments are useful to identify positive and
negative sentiment regarding products or campaigns and contain useful insights which can
help corporations to come out with strategies to reduce negativity, build effective campaigns
to improve sales, review and revenue. As such the domain of natural language processing
sentiment analysis is selected. As deriving sentiment is complicated the paper aim to research
how deep learning models can assist in predicting and classifying customers opinions and
sentiments.
1.3 Aim and objective
The aim and objective of the research is to:
• Explore various deep learning models and how effective and useful they are for
sentiment analysis
• Develop deep learning models to perform the sentiment analysis
• To analyze what preprocessing and transformation is needed before review data can
be used for sentiment.
2
• Review on how to improve model performance to improve model accuracy for better
sentiment analysis which is beneficial to corporations.
The significance of the result of the study is to come out with an efficient model that can
perform sentiment analysis classification which can be useful for companies and corporations
to derive insights which can help them to better review sentiments and build better strategies
based on those findings.
1.4 Literature Review/Previous Works
Sentiment analysis in the context of data science as a classification problem. It needs a
traditional machine learning model or deep learning models utilizing neural networks to
predict or classify sentiments.
Deep learning models can assist and excel in this as it has the ability to automatically extract
features from text, handle sequential data, capture relationships, handle dependencies and
context and therefore easily capture sentiments.
Below is the review of latest and related survey/literature related to sentiment analysis and
the models they use.
A study by (Hamdallah, 2021) with 180,000 reviews on game, books and movie was used to
analyze sentiment. They utilized Naïve bayes model which is machine learning method and
preprocess using "tidyverse" package and general substring function to remove punctuation,
numbers, white spaces and stop words and achieved 79% accuracy. Although not as good as
deep learning models the preprocessing steps are useful insights.
SVM with accuracy of 69.78% to 76.20% for sentiment analysis of how useful is a review.
(Du, Rong, Michalska, Wang, & Zhang, 2019) proof that traditional machine learning
methods cannot perform sentiment analysis as well as Deep learning.They utilized 6
categories from Amazon review 5 core dataset. They retain only reviews with high votes and
preprocess by removing blanks/non-english and lower casing the words and tokenized it
which is also useful insight for this paper experiment.
A research utilizing DNN LSTM deep learning hybrid architecture and with 12 categories
from Amazon review 5-core dataset (Norinder & Norinder, 2022) have an accuracy between
89.8 to 92.2%.It has preprocessing like removing non alpha numeric, removing stop words,
padding with 0 and limit length to 250 and tokenizing. They also hypertuned by
experimenting with the DNN layer, vocab size, undersampling/oversampling when needed
3
and apply conformal prediction to their model. They shown that preprocessing and
hyperparameter tuning can have an impact on the accuracy/results.
A study using transformer based deep learning architecture and several other models utilizing
150,000 train data, 30,000 test data of Amazon review (Noriega, Alvarez, Ramírez, & Cantu-
Ortiz, 2023) have an accuracy of 82% for RoBerta model. They tested on Bert, RoBerta,
XLNet, UMFit and applied TF-IDF and K-means clustering to remove non-useful words.
An SVM model which uses RNN deep learning model to process the sentiment then feed to
SVM model have an accuracy of 81.29% based on a subset of 3.5 mil amazon product review
(Shrestha & Nasoz, 2019).It proves that the experiment is better off utilizing neural network
directly but the preprocessing steps of removing hyperlink, unwanted words, informal words
conversion and adding space between punctuation is a useful insight.
A BERT deep learning transformed based architecture model achieve 89% accuracy (Ali,
Hashmi, Yayilgan Yildirim, & Shaikh, 2024) utilizing 400,000 reviews with a mix of 80,000
from 5 categories. Thet tested with CNN, LSTM, XLNet models as well. They applied
preprocessing to handle missing value, duplication, lowercase, remove stop words and
tokenization. Their insight on setting low epoch due to computation and time constraint and
tuning on learning rate:0.002 and small batch size of 32 was useful in resolving base model
overfitting in this paper.
A CNN deep learning model based on a mix of data from multiple categories of amazon
review (Joseph, 2022) have 44.27% accuracy with no mention of preprocessing and
hyperparameter tuning. This helps to identify the importance of preprocessing and
hyperparameter tuning for model performance.
A RNN deep learning model achieved 85% accuracy based on 290,000 reviews (Ahmed,
2022) and preprocessed through word embeddings and hypertuned with varying epoch and
word volumes. Is interesting to note that the experiment on other models have the following
accuracy LSTM – 76%,GRU – 80%,CNN – 84%. Another research is also similar
(Alroobaea, 2022). This informs that is worthwhile to experiment with CNN and RNN as in
this case it was higher than LSTM.
An LSTM deep learning model achieved 89% accuracy utilizing 5000 amazon review (Zhou,
2016). The experiment includes FNN model testing and they used GloVe for word
embedding. They hyperparameter tuning involves tweaking the regularizers, learning rate and
4
dropout rate which was important in our own effort to improve this paper models during
hypertuning stage.
A LSTM deep learning model achieved 91.03% accuracy outperforming their SVM model
utilizing 5000 amazon review data (Li, Pan, & Wang, 2024).No tuning was specified but they
preprocessed the data by converting number to 0, removing website data, remove special
character and spaces and lowercase the review word letters.
A LSTM deep learning model achieved 88.02% accuracy when performing sentiment
analysis on IMDB twitter review data (G, Usha, Priyan, Babu, Gokulnath, & Karthick,
2021).Thier CNN model achieved 87.72% accuracy which is close to LSTM performance
which prompted this paper to include CNN in the model build and evaluated.
All the research and survey done will be summarized, compared and evaluated in 1.5
comparison and analysis of the literature review to develop insight and guide in what deep
learning model to build to perform the sentiment analysis.
5
1.5 Comparison and analysis of the literature review
Table 1: Comparison and analysis of the literature review
Based on the above analysis in table 1 traditional machine learning models like SVM and
naïve bayes does not perform as well as Deep Learning methods/models. It is also found
generally that those with preprocessing and hyperparameter tuning applied have a generally
better performance. The highest performance is DNN LSTM with 92.2% followed by BERT
or LSTM at 89% and CNN at 87.72%.Based on the research done by others they mostly use
subset of the data or small to moderate size due to the full dataset being too large. As such I
have selected 60001 sample of the full dataset and also limited the training epoch to 5 due to
time constraints and computational limitations.(During the experiment have attempted 10 but
it takes a very long time and disconnect from the runtime often and goes beyond google
collab runtime limit of 90 minutes) so based on another’s research (Ali, Hashmi, Yayilgan
Literature Review Data specification Preprocessing Model Details Hyperparameters Results
(Hamdallah, 2021)
180,000 review rows(3 variable)
from game,movie,book products categories (Amazon
review)
Using "tidyverse" package and
general substring function
to remove punctuation,
numbers, white spaces and stop
words Naïve bayes (80/20 Train test split) Not specified Naïve Bayes 79%
(Du, Rong, Michalska, Wang, & Zhang, 2019) 6 categories from Amazon 5-core dataset
1.Blank/Non english review
filtered out.
2.For identical review only
highest votes retained.
3.Review with lest votes removed
Chosen review are lowercased
and tokenized.
SVM (80 Train/10 Test/10 Validate split) Feature selection focusing on 5S SVM - 69.78% to 76.20%
(Norinder & Norinder, 2022) 12 categories from Amazon 5-core dataset
1.Non-alpha numeric and
english stop words
removed from review text.
2.Review text is tokenized.
3.0 filled right padded with length
250. DNN LSTM (80/20 Train Test Split)
1.Experiment with vocab size.
2.Diff size node in DNN layer
3.Over/Undersampling for
balancing
4.Applying conformal prediction DNN LSTM - 89.8 to 92.2%
(Noriega, Alvarez, Ramírez, & Cantu-Ortiz, 2023) 150,000 train data, 30,000 test data (Amazon review)
TF-IDF and K-means clustering to
remove
non useful words
Bert, RoBerta,XLNet,UMFit (83/17
Train Test Split) Not specified RoBerta - 82%
(Shrestha & Nasoz, 2019) Subset of 3.5mil Amazon product review
1. Removing hyperlinks.
2. Removing unwanted spaces
between words.
3. Converting informal words
such as ‘I’ll’, ‘I’ve’ to its formal
form ‘I will’, ‘I have’, etc.
4. Adding spaces between
punctuation. Punctuations are
treated as separate tokens to try
to improve the
accuracy of the classifier. RNN for sentiment but feed to SVM Not specified
RNN output
to SVM - 81.29%
(Ali, Hashmi, Yayilgan Yildirim, & Shaikh, 2024)
400,000 reviews with a mix of
80,000 from 5 categories fr0m Amazon
Handling missing value and
duplication,
case transformation, stop words
removal and tokenzation
CNN
LSTM
XLNet
Bert
(80/20 Train test split)
Epoch 5
Learning rate:0.002%
Batch size: 32
Optimizer:Adam Bert - 89%
(Joseph, 2022)
Mix of data from multiple categories
for Amazon review Not specified CNN Not specified CNN - 44.27%
(Ahmed, 2022) 290,000 Amazon review Through word embeddings
RNN
LSTM
GRU
CNN Varying epoch or word volume
RNN - 85%
LSTM - 76%
GRU - 80
CNN - 83%
(Zhou, 2016) 5000 Amazon review GloVe for embedding word vectors
FNN
LSTM
FNN Regularization rate:0.004
FNN Learning rate:0.005
FNN Dropout rate:0.85
LSTM Regularization rate:0.001
LSTM Learning rate:0.001
LSTM Dropout rate:0.9 LSTM - 89%
(Alroobaea, 2022) 290,000 Amazon review Through word embeddings
RNN
LSTM
GRU
CNN Varying epoch or word volume
RNN - 85%
LSTM - 76%
GRU - 80
CNN - 83%
(Li, Pan, & Wang, 2024) 5000 Amazon review
1.Convert numbers to 0
2.Remove website data
3.Remove special characthers
and spaces
4.Lowercase letters
LSTM
SVM Not specified LSTM - 91.03%
(G, Usha, Priyan, Babu, Gokulnath, & Karthick, 2021) Amount not specified.
1.Words are tokenize
2.Word2Vec embedding model
used
3.Stop words removed CNN
LSTM Not specified
CNN - 87.72%
LSTM - 88.02%
6
Yildirim, & Shaikh, 2024) have use 5 epoch similar to their parameter. Majority of them did
some form of preprocessing and as such this experiment will apply preprocessing like lower
case the text, remove special characters, numbers and punctuation to reduce noise in the data
and make it easier to process by the tokenizer and model. They also tokenized the words and
thus words will be tokenized to allow the model embedding layer to convert them into
vectors for the model to process in the experiment. This experiment will apply tokenization
as well in order to allow the deep learning models to process the words properly. In most they
experimented mostly with epoch, regularizers, learning rate and layer/neuron/node size. The
hypertuning process in this experiment will incorporate changes in hyperparameters as well
as adjusting these hyperparameters can lead to better metrics like higher accuracy, less loss
and a better model fit. Finally in terms of which model to experiment based on the highest
results, this paper will experiment with deep learning models LSTM, DNN-LSTM,CNN and
RNN. In some cases CNN is higher than LSTM and same goes with RNN which is why it
will be good to build these models for evaluation/comparisons in this experiment.
1.6 Overview of the implementation
Below is a brief overview of how the experiment will be implemented
Step 1: The Amazon review data is selected (A subset of 60001 reviews is utilized)
Step 2: The data then is loaded to google colab and the necessary libraries for building
models and evaluation metrics and displaying it are implemented (More details in the ipynb
file)
Step 3: Data is preprocessed and tokenized.
Step 4: 4 models are build evaluated and tuned and evaluated again classifying negative or
positive sentiment through a function utilizing the model and token.
Step 5: The base and hypertuned models are compared internally and with other research
results.
Step 6: The final model is selected.
7
1.7 Dataset used.
The Amazon review polarity dataset is obtained from Kaggle (Acharki, 2021). The data is
originally construed from another research as a classification benchmark (Zhang, Zhao, &
LeCun, 2015). Due to the large size of the data, 60001 review from the overall data have been
used for the experiment. Based on Figure 1,The data consists of the class index where 2 is
positive sentiment and 1 is negative sentiment, the review title and the review text.
Figure 1: Preview of dataset content
1.8 Selected Model Architecture.
Based on the results of the literature review, the model LSTM,CNN,DNN LSTM and RNN is
selected as the model we are going to be build. Further details of how it works is explained
on Assignment 2.3 Base models implementation and evaluation. Below is an explanation of
the selected models. (Goodfellow, Bengio, & Courville, 2016)
LSTM (Long short term memory) is a special type of RNN developed to address vanishing
gradient problems. It has input, forget and output gates to control information flow and act as
a form of memory. It understand context for longer sentences and is useful for understanding
sentiment and usually perform well for sentiment analysis
CNN (Convolutional Neural Network) use convolutional filters to extract patterns (N-grams)
from text. It can capture patterns in text like phrases or sentences which are of positive or
negative sentiments. It can be effective for sentiment analysis.
DNN LSTM (Deep Neural Network Long Short Term Memory Hybrid architecture) Is a
hybrid architecture which uses DNN fully connected layers to process input to feed into
LSTM for sequential processing. DNN learns the from patterns while LSTM learns from
sequences. It attempts to utilize the strength of both architecture and perform generally well
in sentiment analysis.
8
RNN (Recurrent Neural Network) process words and update the hidden state to capture the
meaning and context which can be used to deduce the sentiment. It can perform reasonably
well but may encounter vanishing gradient problems.
1.9 Selected evaluation metrics and criteria.
The evaluation metric that is selected is accuracy,F1,precision and recall which is used to
evaluate the models (James, Witten, Hastie, & Tibshirani, 2021), binary crossentropy for loss
(Hastie, Tibshirani, & Friedman, 2009).
The following are vital components used in the formulas in the evaluation metric:
• True Positive (TP): Correctly predicted positive (Actual = prediction)
• True Negative (TN): Correctly predicted negative (Actual not the same as prediction)
• False Positive (FP): Incorrectly predicted positive (Actual = prediction)
• False Negative (FN): Incorrectly predicted negative (Actual not the same as
prediction)
Accuracy measure how much of the predictions are correct. The higher the accuracy the more
correct predictions the modal makes(James et al., 2021).
Formula: Accuracy = (TP + TN) / (TP + TN + FP + FN).
F1 score combines precision and is useful when dataset is imbalance. A high F1 means a
precision and recall is balanced. (James et al., 2021)
Formula: F1 = (2 x TP) / (2 x TP + FP + FN) or can be interpreted as F1 = 2 x (Precision x
Recall) / (Precision + Recall)
Precision is how much accurate positive predictions made from all the values that are
classified as positive(Both the false and true positives). Higher precision means more true
positive and lower false positive.(James et al., 2021):
Formula: Precision = TP/ (TP + FP)
9
Recall is how high is the true positive cases identified correctly from actual positive cases.
Higher recall means modal can identify true positive. (James et al., 2021)
Formula: Recall = TP / (TP + FN)
Binary crossentropy or log loss is for binary classification and helps to quantify the difference
between predicted and true labels. (Hastie, Tibshirani, & Friedman, 2009)
With the survey/review done, models and data selected, a general plan of implementation and
evaluation metrics determined we can proceed to build and evaluate the model which will be
covered in assignment 2.
Assignment 2 Deep Learning Model Implementation for
Amazon review sentiment analysis.
The assignment will go through the data preprocessing and transformation done on the data,
the building of the base models LSTM,CNN,DNN LSTM,RNN and the hypertuning of the
models. The evaluation and validation on both base and tuned models. The final model will
then be selected and compared to models from other research. Finally the findings will be
summarized in a conclusion and future works/recommendation made based on the findings.
2.1 Data preprocessing.
Figure 2: Preprocessing of dataset
10
Figure 3: Application of preprocessing function to the 60001 review dataset.
Figure 4: Before(Left) and after(Right) preprocessing of review text
Based on Figure 2 a function is created to remove lower case, special characters, numbers
and punctuation this allows for better tokenization and interpretation of the words in the
review text and better model performance. As per Figure 3, the dataset is extracted and
limited to 60001 reviews and the preprocessing function applied. On Figure 4 it shows that
the preprocessing function was successfully applied on the right of the image.
2.2 Data Transformation.
Figure 5: Balancing attempt distribution
11
Figure 6: Tokenization and padding
The data transformation process involving splitting the data to train and test with as balanced
class distribution as possible and tokenizing the review words for the models processing.
Based on Figure 5, the data is split to train and test by 80% train and 20% test with stratify
applied. This is to attempt to preserve the balance of distribution of positive and negative
classes for both train and test. As per illustrated both train and test class distribution are close
with one another. Since it is only slightly unbalanced towards one class no upsampling or
downsampling was applied. Setting it to random state= 42 helps the data to be split the same
every iteration it is run.
The split has to be done before tokenization in order to prevent data leakage and train the
tokenizer only on the train set.
Based on figure 6, The tokenizer out-of-vocabulary(OOV) token converts any word not in the
vocabulary to UNK. The tokenizer then learns from the training set to build mapping of
words to number indexes. This is because the deep learning model can only process numbers
and not text. Next it will be padded by 0.
The text to sequence then transform both the train and test data integer which represent a
word in the vocabulary while pad to sequence set the length to 200. Shorter reviews less than
200 are padded with 0 on the end. If is more than 200 then it will be truncated to 200. This
will allow the model to be trained and tested properly during model build and test prediction.
12
2.3 Base Model implementation and evaluation.
Figure 7: LSTM base model
Figure 8: LSTM base model accuracy and loss
Figure 9: LSTM base model classification report
Based on Figure 7 The LSTM base model embedding layer took the words and embed them
to vectors which is streamlined to 200 in length. The LSTM layers with 128 neurons then
attempt to process the sequential data and capture long term dependencies. The output
dimension then attempts to capture the semantic relation between the words and is set to 1 as
we only want the output to either be 1 positive or 0 negative. Dropout and recurrent dropout
13
of 0.4 was utilized to improve regularization and a regularizer of 0.001 is used to attempt to
prevent overfitting. The sigmoid activation is utilized cause it outputs either a 0 and 1 which
is suitable for this experiment classification which outputs 0 for negative and 1 for positive.
Adam have the benefits of both momentum (which accelerate the optimizer to the right
direction) and RMSprop (which adapts the learning rate for parameters) and function well
with a wide variety of tasks. Binary classification is usually used for binary outputs of 0 and 1
and therefore pairs well with sigmoid. Accuracy metrics is the most commonly used
especially for comparing model performances. The default learning rate is used when not
specified.
Based on Figure 8 The LSTM base model training accuracy is extremely high and testing
accuracy is extremely low. The Testing loss is extremely high and training accuracy is
extremely low. Both did not converge. This shows that the model is severely overfitting.
Based on Figure 9, The LSTM base model overall performance of average 84% is decent but
due to the model overfitting is not suitable to be used as it is.
Figure 10: CNN base Model
Figure 11: CNN base model accuracy and loss
14
Figure 12:CNN based model classification report
Based on Figure 10 The CNN base model consist of embedding layers which convert
words(Which are already transformed to numbers) into vectors/word embeddings. The 3
convolutional layers have 64 kernel which look at 4 words at a time to perform convolution
on the embeddings and identify patterns. Max pool control the feature output to 2 which helps
optimize computation. Relu means it outputs either 1 or 0 and is computationally effective
and helps mitigate vanishing gradient issues. Padding set to same means input and output has
same length to avoid model processing issue. Flatten converts the output from convolutional
to be fed to the dense layer. The dense 256 layer helps to capture features from the
convolutional layer. Dropout of 0.1 helps reduce complexity of the model and prevents
overfitting as well. A small learning rate of (1e-4) was utilized.
The reason sigmoid activation, Adam optimizer, Binary classification for loss and accuracy
for metrics is used is the same as the rest of the models using similar parameter.
Based on Figure 11 The CNN base model test accuracy plateaus and testing loss is increasing
while and training accuracy is increasing and training loss decreases. This means that the
model is overfitting.
Based on Figure 12, The CNN base model overall performance of average 87% is good but
due to the model overfitting is not suitable to be used as it is.
15
Figure 13: DNN LSTM base model
Figure 14: DNN LSTM accuracy and loss
Figure 15: DNN LSTM classification report
Based on Figure 13 The DNN LSTM hybrid consist of embedding layers which convert
words(Which are already transformed to numbers) into vectors/word embeddings. The LSTM
layer (64) is used to capture sequential information. The dense layer (128,64,1) is for
processing of the information with 1 being the binary output layer. It has dropout (0.3
LSTM,0.4 Dense) to improve regularization. Relu means it outputs either 1 or 0 which helps
mitigate vanishing gradient issues and has a learning rate of 0.001 which is not too large or
small.
16
The reason sigmoid activation, Adam optimizer, Binary classification for loss and accuracy
for metrics is used is the same as the rest of the models using similar parameter.
Based on Figure 14 The DNN LSTM test accuracy decreases and testing loss is increasing
while and training accuracy is increasing and training loss decreases. This means that the
model is overfitting.
Based on Figure 15, The DNN LSTM overall performance of average 86%(With 85% on
precision) is good but due to the model overfitting is not suitable to be used as it is.
Figure 16: RNN base model
17
Figure 17:RNN base model accuracy and loss
Figure 18:RNN base model classification report
Based on Figure 16 The RNN base model consist of embedding layers which convert
words(Which are already transformed to numbers) into vectors/word embeddings. The simple
RNN layer (128,64,32) is used to process sequenced data and learn hierarchical relations if
there is any. The dense output layer (1) is the binary output of 0 or 1. Relu means it outputs
either 1 or 0 which helps mitigate vanishing gradient issues and has a learning rate of 0.0001
which on the smaller end.
The reason sigmoid activation, Adam optimizer, Binary classification for loss and accuracy
for metrics is used is the same as the rest of the models using similar parameter.
Based on Figure 17 The RNN base model test accuracy decreases and testing loss is
increasing while and training accuracy is increasing and training loss decreases. This means
that the model is overfitting.
Based on Figure 18, The RNN base model overall performance of average 86% is good but
due to the model overfitting is not suitable to be used as it is.
Overall all the models are overfitting and despite decent performance based on the
classification report on test or unseen data we should be hypertuning the model and choose a
model with an overall better results and better fit on the models.
18
2.4 Hyperparameter Tuning of the base model.
Figure 19: LSTM tuned model
Figure 20:LSTM tuned model accuracy and loss
Figure 21:LSTM tuned model classification report
19
Please note some of the model are tuned multiple times, only the best results are explained on
the paper.
Based on Figure 19, The embedding dimensions in the LSTM tuned model and the LSTM
units were reduced to reduce model complexity to avoid overlearning. The dropout have been
increased from 0.4 to 0.5 from base model for better regularization (Please note the comment
mentioned maintain because it was maintained from the 1st hypertune attempt but only the
best hypertune of the model is included in the paper.) A regularizer (0.001) was added to
penalize large weights to reduce overfitting. And small learning rate(0.0001) and batch size
(32) leads to better convergence and prevent overshoot which try to address overfitting issue.
Based on Figure 20, The LSTM tuned model training accuracy and test accuracy converge
closely with one another by the 4th epoch and the validation accuracy and loss are close by
the 5th epoch meaning that the model has a close fit and is therefore better than the base
model.
Based on Figure 21, the LSTM tuned model have a decent accuracy, precision, recall and F1
of 84% when tested with test/unseen data which is a decent performance although still equal
to base performance.
Figure 22: CNN tuned model
20
Figure 23: CNN tuned model accuracy and loss
Figure 24:CNN tuned model classification report
Based on Figure 22, The CNN tuned model has 3 convolutional layer which were reduced
from 64 to 32 and dense 256 reduced to 64 to reduce model complexity to avoid
overlearning. The dropout have been increased from 0.1 to 0.6 from base model for better
regularization. A regularizer (0.001) was added to penalize large weights to reduce
overfitting. And small learning rate(0.00005) and batch size (32) leads to better convergence
and prevent overshoot which is to prevent overfitting issue.
Based on Figure 23, The CNN tuned model training accuracy and test accuracy converge
closely and the validation accuracy and loss converged closely as well meaning that the
model has a close fit. This mean it has a better fit than the base model.
Based on Figure 24, the CNN tuned model have a good accuracy, precision, recall and F1 of
88% when tested with test/unseen data which is a good performance and has a higher
performance than base model.
21
Figure 25: DNN LSTM tuned model
Figure 26: DNN LSTM tuned model accuracy and loss
Figure 27: DNN LSTM tuned model classification report
Based on Figure 25, The DNN LSTM tuned model have LSTM layer which was reduced to
32 and dense 64,32 to reduce model complexity to avoid overlearning. The dropout have
been increased to 0.6 for better regularization. A small learning rate(0.00008) and batch size
(32) is used to try to get better convergence and prevent overshoot to prevent overfitting
issue.
22
Based on Figure 26, The DNN LSTM tuned model training accuracy and test accuracy
converge more closely and the validation accuracy and loss converged more closely as well
but still shows plateauing test accuracy and increasing test loss meaning although
performance is better than base it is still overfitted.
Based on Figure 27, the DNN LSTM tuned model have a accuracy, precision, recall and F1
of 87% when tested with test/unseen data which is a better performance than the base model.
Figure 28: RNN tuned model
Figure 29: RNN tuned model accuracy and loss
23
Figure 30: RNN tuned model classification report
Based on Figure 28, The RNN tuned model simple RNN layer with (128) is replaced with
LSTM layer (16) to reduce model complexity to avoid overlearning and to better capture
sequence and long term dependencies. A small learning rate(0.00005) and batch size (32) is
used to try to get better convergence and prevent overshoot to prevent overfitting issue. This
also turns it to a hybrid architecture of RNN LSTM.
Based on Figure 29, The RNN LSTM tuned model training accuracy and test accuracy
converge more closely and the validation accuracy and loss converged more closely as well
but still shows plateauing test accuracy and increasing test loss meaning although
performance is better than base it is still overfitted.
Based on Figure 30, the RNN LSTM tuned model have accuracy, precision, recall and F1 of
86% when tested with test/unseen data which is equal performance with the base model.
Based on the overall findings of the hypertuned model the close fit models should be
considered more than the overfitted models based on the validation using accuracy and loss
graph despite all of them having decent test performance from the the classification report as
a close fit model will have better generalization and overall more stable performance with
unseen data. In this case the CNN tuned model will be the final build selected however
further and detailed comparison/evaluation with all the base model and all hypertuned model
should be done to critically analyze before finalizing the decision.
2.5 Critical analysis and comparison of base and hypertuned model.
Table 2: Comparison of results of own base and hypertuned model.
All the base model and tuned model classification report results which is done based on test
and unseen data and the finding based on the graph and results on accuracy and loss of the
models is summarized in Table 2 to evaluate and validate the results of the experiment.
Models Accuracy Precision Recall F1 socre Layer Details Activation function Output Layer Function Dropout Learning Rate Batch size Fit Epoch
LSTM (Base Model) 84% 84% 84% 84% LSTM layer unit -128 tanh(Default) Sigmoid 0.4 0.001(Default) 64 Severely Overfit 5
LSTM (Tuned Model - 2nd attempt) 84% 84% 84% 84%
LSTM layer unit -32
L2_regulaizers -0.001 tanh(Default) Sigmoid 0.5 0.0001 32 Close Fit 5
CNN (Base Model) 87% 87% 87% 87%
Convolution layer - 64
Kernel - 4
Dense - 256 relu Sigmoid 0.1 0.0001 64 Overfit 5
CNN (Tuned Model) 88% 88% 88% 88%
Convolution layer - 32
Kernel - 4
Dense - 64
L2_regulaizers -0.001 relu Sigmoid 0.6 0.00005 32 Close Fit 5
DNN LSTM (Base Model) 85% 86% 85% 85%
Dense layer 128,65
LSTM layer 128 relu Sigmoid
LSTM 0.3
DNN 0.4 0.001 64 Overfit 5
DNN LSTM (Tuned Model - 2nd attempt) 87% 87% 87% 87%
Dense layer 64,32
LSTM layer 32 relu Sigmoid 0.6 for all 0.00008 32 Overfit 5
RNN (Base Model) 86% 86% 86% 86% Simple RNN 128,64,32 relu Sigmoid None 0.0001 32 Overfit 5
RNN LSTM( Tuned Model includes LSTM layer) 86% 86% 86% 86%
RNN 128,64,32
LSTM 16 relu Sigmoid None 0.00005 32 Overfit 5
*Note: classification report is done on test/unseen data
24
Based on the experiment we should be avoiding selecting severely overfitted/overfitted
model despite the strong test performance which mean the base and tuned models of DNN
LSTM,RNN and RNN LSTM should not be selected.
From the overall results it can be deduced that high dimensionality/complexity models with
high neuron/node/kernels, higher learning rate, higher batch size, less dropout or no
regularizers perform poorly and has a tendency to overfit.
This is because it will have a higher tendency to memorize the training data and patterns,
leading to poor performance/generalization with unseen data hence the higher tendencies for
overfitting.
Furthermore Higher Neuron/Node/Kernal may lead it to overlearn, high learning rate may
lead it to overshoot optimal solution and fail to converge (As demonstrated in LSTM base
model), higher batch size which cause it to see more data which might lead to memorization,
less dropout means its less robust when learning and less dropout means there is no penalty
for learning large weights which can lead to overfitting.
In contrast, there seems to be better result or model fit when dimensionality/complexity is
reduced with lower neuron/node/kernels, lower learning rate, lower batch size, higher dropout
and regularizers are added to the model. This is because it reduces the model tendency to
memorize training data and leads to better generalize better to unseen data leading to better
performance.
This is because lower learning rate and batch size allows it to converge better and find better
minima. Higher dropout increase regularization and regularization helps penalize large
weights which prevent overfitting. The lower complexity reduce the tendency to overlearn the
patterns as well.
Based on that we are left with CNN tuned model and LSTM tuned model which have a close
fit between the train and test accuracy and loss. Since CNN has an average of 88% in all
parameters(Accuracy, Precision, Recall and F1) and is higher than LSTM results. The high
precision means the accuracy of positive prediction is high, high recall meaning positive
instances were correctly identified most of the time and high F1 meaning there is a good
balance between precision recall. This means the CNN tuned model should be our
final/selected model to perform the sentiment analysis.
25
2.6 Critical analysis and comparison with other research.
Table 3: Comparison of results with other research
Based on the Table 3,the comparison of own model with the accuracy or outcome of other
research. This experiment CNN tuned accuracy is the highest at 88% and the accuracy is still
higher than a lot of other studies models and the gap with the highest accuracy from DNN
LSTM is only about 3%-4% which is within acceptable range as it is comparable or minimal
difference with other research models with high accuracy.
Most likely we cant achieve as high with the highest accuracy due to data size, data
distribution shape, different architecture layer/neuron/node value, different parameter tuning
like learning rate, regularizers and dropout, slight variance in preprocessing and the
randomness from the iteration of training/testing the model.
Nonetheless, based on the evaluation from the comparison between own models and with the
work of others. The CNN model (Hypertuned version) is selected as the final model build as
it’s accuracy of 88% outperform the rest of the other models, has a close fit, generally strong
performance in classifier report metrics (Precision,F1,Recall) and when compared to others
research accuracy is close/comparable to their results.
Using a function/program to use the trained model and tokenizer we can use it to predict the
sentiment of any review/new review which has prove the model is working and successful as
per demonstrated in Figure 31.
Model CNN LSTM DNN LSTM RNN RNN LSTM Naïve bayes SVM RoBerta BERT
Own Model 88.00% 84.00% 87.00% 86.00% 86.00% N/A N/A N/A N/A
(Hamdallah, 2021) N/A N/A N/A N/A N/A 79.00% N/A N/A N/A
(Du, Rong, Michalska, Wang, & Zhang, 2019) N/A N/A N/A N/A N/A N/A 69.78% to 76.20% N/A N/A
(Norinder & Norinder, 2022) N/A N/A 89.8 to 92.2% N/A N/A N/A N/A N/A N/A
(Noriega, Alvarez, Ramírez, & Cantu-Ortiz, 2023) N/A N/A N/A N/A N/A N/A N/A 82.00% N/A
(Shrestha & Nasoz, 2019) N/A N/A N/A N/A N/A N/A 81.82% N/A N/A
(Ali, Hashmi, Yayilgan Yildirim, & Shaikh, 2024) N/A N/A N/A N/A N/A N/A N/A N/A 89.00%
(Joseph, 2022) 44.27% N/A N/A N/A N/A N/A N/A N/A N/A
(Ahmed, 2022) 83.00% 76.00% N/A 85.00% N/A N/A N/A N/A N/A
(Zhou, 2016) N/A 89.00% N/A N/A N/A N/A N/A N/A N/A
(Alroobaea, 2022) 83.00% 76.00% N/A 85.00% N/A N/A N/A N/A N/A
(Li, Pan, & Wang, 2024) N/A 91.03% N/A N/A N/A N/A 85.44% N/A N/A
(G, Usha, Priyan, Babu, Gokulnath, & Karthick, 2021) 87.74% 88.02% N/A N/A N/A N/A N/A N/A N/A
*Note the table represent comparison of model accuracy with other research paper
26
Figure 31: Sentiment analysis function
3. Conclusion.
From the experiment that have been done, it can be concluded that surveying the deep
learning methods that is generally use for sentiment analysis is useful as by comparing their
different architecture/approaches it can help us to design the appropriate model and approach
to build a deep learning model for sentiment analysis. The experiment also highlights the
importance of hyperparameter tuning like adjusting learning rate, reducing
dimensionality/complexity by reducing filter/kernel/neurons/node in the neural network layer,
including regularizers, increasing dropout to reduce complexity and reducing batch size to
allow better generalization of the model and improved accuracy as it help to improve model
performance and accuracy and reduce overfitting. The CNN hypertuned model has a strong
accuracy of 88% and strong performance with test/unseen data with 88% average on
precision,f1 and recall and is selected as the final build. The model and the trained token also
shows using a function/program that it is able to predict review sentiments correctly and
therefore the experiments done successfully achieve the objective of performing sentiment
analysis for the Amazon review data and is useful in classifying positive and negative
sentiment of reviews.
4. Future work and recommendations.
If there are more computational resources and time it will be great to train with more epoch,
train with bigger dataset than the current sample size and to experiment with more
hyperparameter tuning like reducing the embedding dimension to combat overfitting(It is
possible that the high embedding dimension could be the cause of the overfitting on base and
27
some of the hypertuned model), test with other numbers of layer/neuron/kernel size, further
adjustment of learning rate and regularizers especially with the CNN and LSTM model as
their performance can be close with one another in various studies. For the DNN LSTM and
RNN/RNN LSTM other than parameters adjustment like the above it might need dropout to
combat the tendency of overfitting in future experiment of the models.
References.
1.Acharki.Y (2021). Amazon Reviews for SA-Binary - Negative/Positive. Kaggle.
https://www.kaggle.com/datasets/yacharki/amazon-reviews-for-sa-binary-negative-
positive-csv/data
2. Zhang, X., Zhao, J., & LeCun, Y. (2015). Character-level convolutional networks for text
classification. Advances in Neural Information Processing Systems, 28.
3. G, Usha., Priyan, M. K., Babu, C., Gokulnath, C., & Karthick, G. (2021). Sentiment
Analysis on Twitter Data by Using Convolutional Neural Network (CNN) and Long Short
Term Memory 1 (LSTM).. 10.21203/rs.3.rs-247154/v1.
4.Hamdallah, Ammar Rashed, "Amazon Reviews using Sentiment Analysis" (2021).
Thesis. Rochester Institute of Technology.
5. Du J, Rong J, Michalska S, Wang H, Zhang Y (2019) Feature selection for helpfulness
prediction of online product reviews: An empirical study. PLoS ONE 14(12): e0226902.
https://doi.org/10.1371/journal.pone.0226902
6. Noriega, Isabella & Alvarez, Héctor & Ramírez, Carlos & Cantu-Ortiz, Francisco.
(2023). Sentiment Analysis of Amazon Reviews using Deep Learning Techniques.
10.13140/RG.2.2.35547.75046.
7.Shrestha, N., & Nasoz, F. (2019). Deep Learning Sentiment Analysis of Amazon.com
Reviews and Ratings. ArXiv, abs/1904.04096.
8.Ali, H., Hashmi, E., Yayilgan Yildirim, S., & Shaikh, S. (2024). Analyzing Amazon
Products Sentiment: A Comparative Study of Machine and Deep Learning, and
Transformer-Based Techniques. Electronics, 13(7), 1305.
https://doi.org/10.3390/electronics13071305
9.Joseph, M. V. (2022). Sentiment analysis of Amazon reviews using improvised
conditional-based convolutional neural network and word embedding. International
Journal of Engineering Trends and Technology, 70(12), 194–209.
https://doi.org/10.14445/22315381/IJETT-V70I12P220
28
10.Norinder, U., & Norinder, P. (2022). Predicting Amazon customer reviews with deep
confidence using deep learning and conformal prediction. Journal of Management
Analytics, 9(1), 1–16. https://doi.org/10.1080/23270012.2022.2031324
11. Ahmed, I. (2022). Comparative study of sentiment analysis on Amazon product
reviews using recurrent neural network (RNN). International Journal of Advanced Trends
in Computer Science and Engineering, 11(3), May–June.
http://www.warse.org/IJATCSE/static/pdf/file/ijatcse111132022.pdf
https://doi.org/10.30534/ijatcse/2022/111132022
12. Zhou, Z. (2016). Amazon Food Review Classification using Deep Learning and
Recommender System.From <https://www.semanticscholar.org/paper/Amazon-Food-
Review-Classification-using-Deep-and-
Zhou/c2fabcfbdb0476005589728a611010072f485e00>
13. Alroobaea, R. (2022). Sentiment analysis on Amazon product reviews using the
recurrent neural network (RNN). International Journal of Advanced Computer Science
and Applications (IJACSA), 13(4). http://dx.doi.org/10.14569/IJACSA.2022.0130437
14.Li, Jiaqi & Pan, Qi & Wang, Yihao. (2024). Sentiment analysis applied on Amazon
reviews. Applied and Computational Engineering. 44. 26-32. 10.54254/2755-
2721/44/20230079.
15. James, G., Witten, D., Hastie, T., & Tibshirani, R. (2021). An introduction to statistical
learning (Vol. 112, pp. 170-171). Springer.
16. Hastie, T., Tibshirani, R., & Friedman, J. (2009). The elements of statistical learning:
Data mining, inference, and prediction (2nd ed.). Springer.
17. Goodfellow, I., Bengio, Y., & Courville, A. (2016). Deep learning. MIT press.